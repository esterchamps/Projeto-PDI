{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca6dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aad98f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e99566da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53270897",
   "metadata": {},
   "source": [
    "## Constantes (paths, dimensões, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2e95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_train_crack = 'dataset/train/crack/'\n",
    "base_dir_train_non_crack = 'dataset/train/non-crack_random_subset/'\n",
    "base_dir_test_crack = 'dataset/test/crack/'\n",
    "base_dir_test_non_crack = 'dataset/test/non-crack_random_subset/'\n",
    "base_dir_processed_train_images = 'processed-dataset-train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a95572b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_image_name_prefix = 'preprocessed_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37db4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_image_width = 256\n",
    "default_image_height = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e37ce420",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_blur_kernel_size = 3\n",
    "clahe_clip_limit = 4.0\n",
    "clahe_tile_grid_size = (30, 30)\n",
    "first_erosion_iterations = 3\n",
    "first_dilation_iterations = 2\n",
    "size_for_erosion_and_dilation_element = 2\n",
    "\n",
    "element_for_erosion_and_dilation = \\\n",
    "    cv2.getStructuringElement(cv2.MORPH_CROSS, \\\n",
    "                              (2 * size_for_erosion_and_dilation_element + 1, 2 * size_for_erosion_and_dilation_element + 1), \\\n",
    "                              (size_for_erosion_and_dilation_element, size_for_erosion_and_dilation_element))\n",
    "\n",
    "adapt_thresh_neighbour_size = 11\n",
    "adapt_thresh_subtraction_constant = 2\n",
    "\n",
    "sobel_kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8f6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid_for_search = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d8b08",
   "metadata": {},
   "source": [
    "## Funções de pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97538b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_with_grayscale_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                                 images_list, \\\n",
    "                                                                 median_blur_kernel_size, \\\n",
    "                                                                 clahe_clip_limit, \\\n",
    "                                                                 clahe_tile_grid_size, \\\n",
    "                                                                 element_for_erosion_and_dilation, \\\n",
    "                                                                 first_erosion_iterations, \\\n",
    "                                                                 first_dilation_iterations):\n",
    "    \n",
    "    pre_processed_images = []\n",
    "    clahe = cv2.createCLAHE(clipLimit = clahe_clip_limit, tileGridSize = clahe_tile_grid_size)\n",
    "    \n",
    "    for image in images_list:\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # converte para escala de cinzas\n",
    "        blured_image = cv2.medianBlur(grayscale_image, median_blur_kernel_size) # aplica filtro de mediana\n",
    "        clahe_image = clahe.apply(blured_image) # aplica equalizacao de histograma por blocos, uniformiza iluminacao\n",
    "        min_pixel_value = np.min(clahe_image) # obtem o pixel de menor valor na imagem\n",
    "        darker_image = clahe_image - min_pixel_value # escurece toda a imagem, subtraindo o valor do menor pixel\n",
    "        \n",
    "        erosion_image = cv2.erode(darker_image, \\\n",
    "                                  element_for_erosion_and_dilation, \\\n",
    "                                  iterations = first_erosion_iterations) # aplica n erosoes\n",
    "        \n",
    "        dilated_image = cv2.dilate(erosion_image, \\\n",
    "                                   element_for_erosion_and_dilation, \\\n",
    "                                   iterations = first_dilation_iterations) # aplica n dilatacoes\n",
    "        \n",
    "        pre_processed_images.append(dilated_image)\n",
    "        \n",
    "    return pre_processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e525690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_adaptthreshold(\n",
    "                                                                            images_list, \\\n",
    "                                                                            median_blur_kernel_size, \\\n",
    "                                                                            clahe_clip_limit, \\\n",
    "                                                                            clahe_tile_grid_size, \\\n",
    "                                                                            element_for_erosion_and_dilation, \\\n",
    "                                                                            first_erosion_iterations, \\\n",
    "                                                                            first_dilation_iterations, \\\n",
    "                                                                            adapt_thresh_neighbour_size, \\\n",
    "                                                                            adapt_thresh_subtraction_constant):\n",
    "    \n",
    "    pre_processed_images = []\n",
    "    clahe = cv2.createCLAHE(clipLimit = clahe_clip_limit, tileGridSize = clahe_tile_grid_size)\n",
    "    \n",
    "    for image in images_list:\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # converte para escala de cinzas\n",
    "        blured_image = cv2.medianBlur(grayscale_image, median_blur_kernel_size) # aplica filtro de mediana\n",
    "        clahe_image = clahe.apply(blured_image) # aplica equalizacao de histograma por blocos, uniformiza iluminacao\n",
    "        min_pixel_value = np.min(clahe_image) # obtem o pixel de menor valor na imagem\n",
    "        darker_image = clahe_image - min_pixel_value # escurece toda a imagem, subtraindo o valor do menor pixel\n",
    "        \n",
    "        erosion_image = cv2.erode(darker_image, \\\n",
    "                                  element_for_erosion_and_dilation, \\\n",
    "                                  iterations = first_erosion_iterations) # aplica n erosoes\n",
    "        \n",
    "        dilated_image = cv2.dilate(erosion_image, \\\n",
    "                                   element_for_erosion_and_dilation, \\\n",
    "                                   iterations = first_dilation_iterations) # aplica n dilatacoes\n",
    "        \n",
    "        image_threshold = cv2.adaptiveThreshold(dilated_image, 255, \\\n",
    "                                                cv2.ADAPTIVE_THRESH_MEAN_C, \\\n",
    "                                                cv2.THRESH_BINARY, \\\n",
    "                                                adapt_thresh_neighbour_size, \\\n",
    "                                                adapt_thresh_subtraction_constant) # binarização por threshold adaptativo\n",
    "        \n",
    "        pre_processed_images.append(image_threshold)\n",
    "        \n",
    "    return pre_processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da9a943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_sobel(\n",
    "                                                                   images_list, \\\n",
    "                                                                   median_blur_kernel_size, \\\n",
    "                                                                   clahe_clip_limit, \\\n",
    "                                                                   clahe_tile_grid_size, \\\n",
    "                                                                   element_for_erosion_and_dilation, \\\n",
    "                                                                   first_erosion_iterations, \\\n",
    "                                                                   first_dilation_iterations, \\\n",
    "                                                                   sobel_kernel_size):\n",
    "    \n",
    "    pre_processed_images = []\n",
    "    clahe = cv2.createCLAHE(clipLimit = clahe_clip_limit, tileGridSize = clahe_tile_grid_size)\n",
    "    \n",
    "    for image in images_list:\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # converte para escala de cinzas\n",
    "        blured_image = cv2.medianBlur(grayscale_image, median_blur_kernel_size) # aplica filtro de mediana\n",
    "        clahe_image = clahe.apply(blured_image) # aplica equalizacao de histograma por blocos, uniformiza iluminacao\n",
    "        min_pixel_value = np.min(clahe_image) # obtem o pixel de menor valor na imagem\n",
    "        darker_image = clahe_image - min_pixel_value # escurece toda a imagem, subtraindo o valor do menor pixel\n",
    "        \n",
    "        erosion_image = cv2.erode(darker_image, \\\n",
    "                                  element_for_erosion_and_dilation, \\\n",
    "                                  iterations = first_erosion_iterations) # aplica 2 erosoes\n",
    "        \n",
    "        dilated_image = cv2.dilate(erosion_image, \\\n",
    "                                   element_for_erosion_and_dilation, \\\n",
    "                                   iterations = first_dilation_iterations) # aplica 2 dilatacoes\n",
    "        \n",
    "        gradient_x = cv2.Sobel(dilated_image, cv2.CV_64F, 1, 0, ksize=sobel_kernel_size)\n",
    "        gradient_y = cv2.Sobel(dilated_image, cv2.CV_64F, 0, 1, ksize=sobel_kernel_size)\n",
    "        gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "        gradient_magnitude = cv2.convertScaleAbs(gradient_magnitude) # obtém o filtro sobel horizontal e vertical\n",
    "        \n",
    "        pre_processed_images.append(gradient_magnitude)\n",
    "        \n",
    "    return pre_processed_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df415fe",
   "metadata": {},
   "source": [
    "## Demais funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ff9cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_name_list(base_dir, list_with_names, default_image_width, default_image_height):\n",
    "    loaded_images = []\n",
    "    for image_name in list_with_names:\n",
    "        im = cv2.imread(base_dir + image_name)\n",
    "        im_correct_colorscheme = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        im_resized = cv2.resize(im_correct_colorscheme, (default_image_width, default_image_height))\n",
    "        loaded_images.append(im_resized)\n",
    "    return loaded_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37799a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(base_dir, images_list, images_names_list, image_name_prefix, directory_to_save):\n",
    "    for idx in range(len(images_names_list)):\n",
    "        \n",
    "        if not os.path.exists(base_dir + directory_to_save):\n",
    "            os.makedirs(base_dir + directory_to_save)\n",
    "            \n",
    "        cv2.imwrite(base_dir + directory_to_save + '/' + image_name_prefix + images_names_list[idx], images_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf76f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_labels(pre_processed_train_crack, pre_processed_train_non_crack):\n",
    "    input_masks = []\n",
    "    input_masks.extend(pre_processed_train_crack)\n",
    "    input_masks.extend(pre_processed_train_non_crack) # adicionamos todas as imagens à lista de input do modelo\n",
    "    input_labels = []\n",
    "    input_labels.extend(np.ones((len(pre_processed_train_crack), ), np.uint8))\n",
    "    input_labels.extend(np.zeros((len(pre_processed_train_non_crack), ), np.uint8)) # adicionamos as labels das imagens\n",
    "\n",
    "    input_masks = list(map(lambda x:x.flatten(), input_masks)) # aqui, redimensionamos as imagens para terem 1 dimensao\n",
    "\n",
    "    zipped_list_for_shuffle = list(zip(input_masks, input_labels))\n",
    "    random.shuffle(zipped_list_for_shuffle)\n",
    "    \n",
    "    shuffled_input_masks, shuffled_input_labels = zip(*zipped_list_for_shuffle)\n",
    "    \n",
    "    return list(shuffled_input_masks), list(shuffled_input_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f37e8",
   "metadata": {},
   "source": [
    "## Carregando conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "041c085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "crack_images_for_train_name_list = os.listdir(base_dir_train_crack)\n",
    "non_crack_images_for_train_name_list = os.listdir(base_dir_train_non_crack)\n",
    "\n",
    "crack_images_for_test_name_list = os.listdir(base_dir_test_crack)\n",
    "non_crack_images_for_test_name_list = os.listdir(base_dir_test_non_crack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65e27aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "crack_images_for_train_list = load_images_from_name_list(base_dir_train_crack, \\\n",
    "                                                         crack_images_for_train_name_list, \\\n",
    "                                                         default_image_width, default_image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "984c2b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_crack_images_for_train_list = load_images_from_name_list(base_dir_train_non_crack, \\\n",
    "                                                             non_crack_images_for_train_name_list, \\\n",
    "                                                             default_image_width, default_image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65c79b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "crack_images_for_test_list = load_images_from_name_list(base_dir_test_crack, \\\n",
    "                                                         crack_images_for_test_name_list, \\\n",
    "                                                         default_image_width, default_image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ec3978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_crack_images_for_test_list = load_images_from_name_list(base_dir_test_non_crack, \\\n",
    "                                                             non_crack_images_for_test_name_list, \\\n",
    "                                                             default_image_width, default_image_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2510bd4",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56861f01",
   "metadata": {},
   "source": [
    "### Pré-processamento 1: Conversão escala de cinzas, filtro mediana, CLAHE, escurecimento, erosão e dilatação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "464a82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_crack_1 = pre_process_with_grayscale_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                                                       crack_images_for_train_list, \\\n",
    "                                                                                       median_blur_kernel_size, \\\n",
    "                                                                                       clahe_clip_limit, \\\n",
    "                                                                                       clahe_tile_grid_size, \\\n",
    "                                                                                       element_for_erosion_and_dilation, \\\n",
    "                                                                                       first_erosion_iterations, \\\n",
    "                                                                                       first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a5d1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_non_crack_1 = pre_process_with_grayscale_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                                                           non_crack_images_for_train_list, \\\n",
    "                                                                                           median_blur_kernel_size, \\\n",
    "                                                                                           clahe_clip_limit, \\\n",
    "                                                                                           clahe_tile_grid_size, \\\n",
    "                                                                                           element_for_erosion_and_dilation, \\\n",
    "                                                                                           first_erosion_iterations, \\\n",
    "                                                                                           first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c0bd3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_crack_1 = pre_process_with_grayscale_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                                                       crack_images_for_test_list, \\\n",
    "                                                                                       median_blur_kernel_size, \\\n",
    "                                                                                       clahe_clip_limit, \\\n",
    "                                                                                       clahe_tile_grid_size, \\\n",
    "                                                                                       element_for_erosion_and_dilation, \\\n",
    "                                                                                       first_erosion_iterations, \\\n",
    "                                                                                       first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7caaa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_non_crack_1 = pre_process_with_grayscale_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                                                           non_crack_images_for_test_list, \\\n",
    "                                                                                           median_blur_kernel_size, \\\n",
    "                                                                                           clahe_clip_limit, \\\n",
    "                                                                                           clahe_tile_grid_size, \\\n",
    "                                                                                           element_for_erosion_and_dilation, \\\n",
    "                                                                                           first_erosion_iterations, \\\n",
    "                                                                                           first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c9ea580",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_crack_1, \\\n",
    "            crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'crack_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f710d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_non_crack_1, \\\n",
    "            non_crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'non-crack_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b3665",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9183c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_input_data_1, svm_input_labels_1 = get_data_and_labels(pre_processed_train_crack_1, pre_processed_train_non_crack_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b04e5550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_1 = SVC()\n",
    "grid_search_svm_1 = GridSearchCV(svm_model_1, svm_param_grid_for_search, cv=5, scoring='accuracy')\n",
    "grid_search_svm_1.fit(svm_input_data_1, svm_input_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1a44af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_data_1, svm_test_labels_1 = get_data_and_labels(pre_processed_test_crack_1, pre_processed_test_non_crack_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "059ebd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters SVM 1: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Accuracy SVM 1: 0.8333333333333333\n",
      "Test Set Accuracy SVM 1: 0.8407643312101911\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters SVM 1:\", grid_search_svm_1.best_params_)\n",
    "print(\"Best Accuracy SVM 1:\", grid_search_svm_1.best_score_)\n",
    "best_svm_model_1 = grid_search_svm_1.best_estimator_\n",
    "accuracy_1 = best_svm_model_1.score(svm_test_data_1, svm_test_labels_1)\n",
    "print(\"Test Set Accuracy SVM 1:\", accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9367cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_prediction_1 = best_svm_model_1.predict(svm_test_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3c5b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_svm_1 = accuracy_score(svm_test_prediction_1, svm_test_labels_1)\n",
    "precision_svm_1 = precision_score(svm_test_labels_1, svm_test_prediction_1)\n",
    "recall_svm_1 = recall_score(svm_test_labels_1, svm_test_prediction_1)\n",
    "f1_svm_1 = f1_score(svm_test_prediction_1, svm_test_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df89682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\", precision_svm_1)\n",
    "print(\"Recall:\", recall_svm_1)\n",
    "print(\"F1-SCORE:\", f1_svm_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53fd585",
   "metadata": {},
   "source": [
    "### Pré-processamento 2: Conversão escala de cinzas, filtro mediana, CLAHE, escurecimento, erosão, dilatação e threshold adaptativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d1f5b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_crack_2 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_adaptthreshold( \\\n",
    "                                                                            crack_images_for_train_list, \\\n",
    "                                                                            median_blur_kernel_size, \\\n",
    "                                                                            clahe_clip_limit, \\\n",
    "                                                                            clahe_tile_grid_size, \\\n",
    "                                                                            element_for_erosion_and_dilation, \\\n",
    "                                                                            first_erosion_iterations, \\\n",
    "                                                                            first_dilation_iterations, \\\n",
    "                                                                            adapt_thresh_neighbour_size, \\\n",
    "                                                                            adapt_thresh_subtraction_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "080e1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_non_crack_2 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_adaptthreshold( \\\n",
    "                                                                            non_crack_images_for_train_list, \\\n",
    "                                                                            median_blur_kernel_size, \\\n",
    "                                                                            clahe_clip_limit, \\\n",
    "                                                                            clahe_tile_grid_size, \\\n",
    "                                                                            element_for_erosion_and_dilation, \\\n",
    "                                                                            first_erosion_iterations, \\\n",
    "                                                                            first_dilation_iterations, \\\n",
    "                                                                            adapt_thresh_neighbour_size, \\\n",
    "                                                                            adapt_thresh_subtraction_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3db202bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_crack_2 = pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_adaptthreshold( \\\n",
    "                                                                            crack_images_for_test_list, \\\n",
    "                                                                            median_blur_kernel_size, \\\n",
    "                                                                            clahe_clip_limit, \\\n",
    "                                                                            clahe_tile_grid_size, \\\n",
    "                                                                            element_for_erosion_and_dilation, \\\n",
    "                                                                            first_erosion_iterations, \\\n",
    "                                                                            first_dilation_iterations, \\\n",
    "                                                                            adapt_thresh_neighbour_size, \\\n",
    "                                                                            adapt_thresh_subtraction_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49baec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_non_crack_2 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_adaptthreshold( \\\n",
    "                                                                            non_crack_images_for_test_list, \\\n",
    "                                                                            median_blur_kernel_size, \\\n",
    "                                                                            clahe_clip_limit, \\\n",
    "                                                                            clahe_tile_grid_size, \\\n",
    "                                                                            element_for_erosion_and_dilation, \\\n",
    "                                                                            first_erosion_iterations, \\\n",
    "                                                                            first_dilation_iterations, \\\n",
    "                                                                            adapt_thresh_neighbour_size, \\\n",
    "                                                                            adapt_thresh_subtraction_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9d45ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_crack_2, \\\n",
    "            crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'crack_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "763ccf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_non_crack_2, \\\n",
    "            non_crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'non-crack_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616655d",
   "metadata": {},
   "source": [
    "Obtendo dados e labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1df7c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_2, input_labels_2 = get_data_and_labels(pre_processed_train_crack_2, pre_processed_train_non_crack_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8eee28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2, test_labels_2 = get_data_and_labels(pre_processed_test_crack_2, pre_processed_test_non_crack_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed712cde",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa8fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_2 = SVC()\n",
    "grid_search_svm_2 = GridSearchCV(svm_model_2, svm_param_grid_for_search, cv=5, scoring='accuracy')\n",
    "grid_search_svm_2.fit(input_data_2, input_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef4bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters SVM 2:\", grid_search_svm_2.best_params_)\n",
    "print(\"Best Accuracy SVM 2:\", grid_search_svm_2.best_score_)\n",
    "best_svm_model_2 = grid_search_svm_2.best_estimator_\n",
    "accuracy_2 = best_svm_model_2.score(test_data_2, test_labels_2)\n",
    "print(\"Test Set Accuracy SVM 2:\", accuracy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_prediction_2 = best_svm_model_2.predict(test_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_svm_2 = precision_score(test_labels_2, svm_test_prediction_2)\n",
    "recall_svm_2 = recall_score(test_labels_2, svm_test_prediction_2)\n",
    "f1_svm_2 = f1_score(svm_test_prediction_2, test_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f5451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\", precision_svm_2)\n",
    "print(\"Recall:\", recall_svm_2)\n",
    "print(\"F1-SCORE:\", f1_svm_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfa6a43",
   "metadata": {},
   "source": [
    "### Pré-processamento 3: Conversão escala de cinzas, filtro mediana, CLAHE, escurecimento, erosão, dilatação e filtro Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041af305",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_crack_3 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_sobel( \\\n",
    "                                                                   crack_images_for_train_list, \\\n",
    "                                                                   median_blur_kernel_size, \\\n",
    "                                                                   clahe_clip_limit, \\\n",
    "                                                                   clahe_tile_grid_size, \\\n",
    "                                                                   element_for_erosion_and_dilation, \\\n",
    "                                                                   first_erosion_iterations, \\\n",
    "                                                                   first_dilation_iterations, \\\n",
    "                                                                   sobel_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_non_crack_3 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_sobel( \\\n",
    "                                                                   non_crack_images_for_train_list, \\\n",
    "                                                                   median_blur_kernel_size, \\\n",
    "                                                                   clahe_clip_limit, \\\n",
    "                                                                   clahe_tile_grid_size, \\\n",
    "                                                                   element_for_erosion_and_dilation, \\\n",
    "                                                                   first_erosion_iterations, \\\n",
    "                                                                   first_dilation_iterations, \\\n",
    "                                                                   sobel_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65218a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_crack_3 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_sobel( \\\n",
    "                                                                   crack_images_for_test_list, \\\n",
    "                                                                   median_blur_kernel_size, \\\n",
    "                                                                   clahe_clip_limit, \\\n",
    "                                                                   clahe_tile_grid_size, \\\n",
    "                                                                   element_for_erosion_and_dilation, \\\n",
    "                                                                   first_erosion_iterations, \\\n",
    "                                                                   first_dilation_iterations, \\\n",
    "                                                                   sobel_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b63d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_non_crack_3 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_sobel( \\\n",
    "                                                                   non_crack_images_for_test_list, \\\n",
    "                                                                   median_blur_kernel_size, \\\n",
    "                                                                   clahe_clip_limit, \\\n",
    "                                                                   clahe_tile_grid_size, \\\n",
    "                                                                   element_for_erosion_and_dilation, \\\n",
    "                                                                   first_erosion_iterations, \\\n",
    "                                                                   first_dilation_iterations, \\\n",
    "                                                                   sobel_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfab9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_crack_3, \\\n",
    "            crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'crack_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_non_crack_3, \\\n",
    "            non_crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'non-crack_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672562c5",
   "metadata": {},
   "source": [
    "Obtendo dados e labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_3, input_labels_3 = get_data_and_labels(pre_processed_train_crack_3, pre_processed_train_non_crack_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_3, test_labels_3 = get_data_and_labels(pre_processed_test_crack_3, pre_processed_test_non_crack_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076288d",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_3 = SVC()\n",
    "grid_search_svm_3 = GridSearchCV(svm_model_3, svm_param_grid_for_search, cv=5, scoring='accuracy')\n",
    "grid_search_svm_3.fit(input_data_3, input_labels_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cacbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters SVM 3:\", grid_search_svm_3.best_params_)\n",
    "print(\"Best Accuracy SVM 3:\", grid_search_svm_3.best_score_)\n",
    "best_svm_model_3 = grid_search_svm_3.best_estimator_\n",
    "accuracy_3 = best_svm_model_3.score(test_data_3, test_labels_3)\n",
    "print(\"Test Set Accuracy SVM 3:\", accuracy_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d3bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_prediction_3 = best_svm_model_3.predict(test_data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641e138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_svm_3 = precision_score(test_labels_3, svm_test_prediction_3)\n",
    "recall_svm_3 = recall_score(test_labels_3, svm_test_prediction_3)\n",
    "f1_svm_3 = f1_score(svm_test_prediction_3, test_labels_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776519f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\", precision_svm_3)\n",
    "print(\"Recall:\", recall_svm_3)\n",
    "print(\"F1-SCORE:\", f1_svm_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
