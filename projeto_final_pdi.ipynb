{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2d8f3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c192746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1806364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87c2ad",
   "metadata": {},
   "source": [
    "## Constantes (paths, dimensões, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8bb0b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_train_crack = 'dataset/train/crack/'\n",
    "base_dir_train_non_crack = 'dataset/train/non-crack_random_subset/'\n",
    "base_dir_test_crack = 'dataset/test/crack/'\n",
    "base_dir_test_non_crack = 'dataset/test/non-crack_random_subset/'\n",
    "base_dir_processed_train_images = 'processed-dataset-train/'\n",
    "base_dir_trained_models = 'trained-models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ed0f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_image_name_prefix = 'preprocessed_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e4ac220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_filename = 'svm_model.pkl'\n",
    "rf_model_filename = 'rf_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_case_dir = 'testing-case-example/Testing/'\n",
    "testing_case_csv_file_name = 'Testing.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3f1e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_image_width = 256\n",
    "default_image_height = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c196a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_blur_kernel_size = 3\n",
    "clahe_clip_limit = 4.0\n",
    "clahe_tile_grid_size = (30, 30)\n",
    "first_erosion_iterations = 3\n",
    "first_dilation_iterations = 2\n",
    "size_for_erosion_and_dilation_element = 2\n",
    "\n",
    "element_for_erosion_and_dilation = \\\n",
    "    cv2.getStructuringElement(cv2.MORPH_CROSS, \\\n",
    "                              (2 * size_for_erosion_and_dilation_element + 1, 2 * size_for_erosion_and_dilation_element + 1), \\\n",
    "                              (size_for_erosion_and_dilation_element, size_for_erosion_and_dilation_element))\n",
    "\n",
    "adapt_thresh_neighbour_size = 11\n",
    "adapt_thresh_subtraction_constant = 2\n",
    "\n",
    "sobel_kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0932acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid_for_search = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c7f4b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid_for_search = {\n",
    "    'n_estimators': [150, 250],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [3, 7],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c028524",
   "metadata": {},
   "source": [
    "## Funções de pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8074f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_with_grayscale_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                                 images_list, \\\n",
    "                                                                 median_blur_kernel_size, \\\n",
    "                                                                 clahe_clip_limit, \\\n",
    "                                                                 clahe_tile_grid_size, \\\n",
    "                                                                 element_for_erosion_and_dilation, \\\n",
    "                                                                 first_erosion_iterations, \\\n",
    "                                                                 first_dilation_iterations):\n",
    "    \n",
    "    pre_processed_images = []\n",
    "    clahe = cv2.createCLAHE(clipLimit = clahe_clip_limit, tileGridSize = clahe_tile_grid_size)\n",
    "    \n",
    "    for image in images_list:\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # converte para escala de cinzas\n",
    "        blured_image = cv2.medianBlur(grayscale_image, median_blur_kernel_size) # aplica filtro de mediana\n",
    "        clahe_image = clahe.apply(blured_image) # aplica equalizacao de histograma por blocos, uniformiza iluminacao\n",
    "        min_pixel_value = np.min(clahe_image) # obtem o pixel de menor valor na imagem\n",
    "        darker_image = clahe_image - min_pixel_value # escurece toda a imagem, subtraindo o valor do menor pixel\n",
    "        \n",
    "        erosion_image = cv2.erode(darker_image, \\\n",
    "                                  element_for_erosion_and_dilation, \\\n",
    "                                  iterations = first_erosion_iterations) # aplica n erosoes\n",
    "        \n",
    "        dilated_image = cv2.dilate(erosion_image, \\\n",
    "                                   element_for_erosion_and_dilation, \\\n",
    "                                   iterations = first_dilation_iterations) # aplica n dilatacoes\n",
    "        \n",
    "        pre_processed_images.append(dilated_image)\n",
    "        \n",
    "    return pre_processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f819388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_adaptthreshold(\n",
    "                                                                            images_list, \\\n",
    "                                                                            median_blur_kernel_size, \\\n",
    "                                                                            clahe_clip_limit, \\\n",
    "                                                                            clahe_tile_grid_size, \\\n",
    "                                                                            element_for_erosion_and_dilation, \\\n",
    "                                                                            first_erosion_iterations, \\\n",
    "                                                                            first_dilation_iterations, \\\n",
    "                                                                            adapt_thresh_neighbour_size, \\\n",
    "                                                                            adapt_thresh_subtraction_constant):\n",
    "    \n",
    "    pre_processed_images = []\n",
    "    clahe = cv2.createCLAHE(clipLimit = clahe_clip_limit, tileGridSize = clahe_tile_grid_size)\n",
    "    \n",
    "    for image in images_list:\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # converte para escala de cinzas\n",
    "        blured_image = cv2.medianBlur(grayscale_image, median_blur_kernel_size) # aplica filtro de mediana\n",
    "        clahe_image = clahe.apply(blured_image) # aplica equalizacao de histograma por blocos, uniformiza iluminacao\n",
    "        min_pixel_value = np.min(clahe_image) # obtem o pixel de menor valor na imagem\n",
    "        darker_image = clahe_image - min_pixel_value # escurece toda a imagem, subtraindo o valor do menor pixel\n",
    "        \n",
    "        erosion_image = cv2.erode(darker_image, \\\n",
    "                                  element_for_erosion_and_dilation, \\\n",
    "                                  iterations = first_erosion_iterations) # aplica n erosoes\n",
    "        \n",
    "        dilated_image = cv2.dilate(erosion_image, \\\n",
    "                                   element_for_erosion_and_dilation, \\\n",
    "                                   iterations = first_dilation_iterations) # aplica n dilatacoes\n",
    "        \n",
    "        image_threshold = cv2.adaptiveThreshold(dilated_image, 255, \\\n",
    "                                                cv2.ADAPTIVE_THRESH_MEAN_C, \\\n",
    "                                                cv2.THRESH_BINARY, \\\n",
    "                                                adapt_thresh_neighbour_size, \\\n",
    "                                                adapt_thresh_subtraction_constant) # binarização por threshold adaptativo\n",
    "        \n",
    "        pre_processed_images.append(image_threshold)\n",
    "        \n",
    "    return pre_processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce9be3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_sobel(\n",
    "                                                                   images_list, \\\n",
    "                                                                   median_blur_kernel_size, \\\n",
    "                                                                   clahe_clip_limit, \\\n",
    "                                                                   clahe_tile_grid_size, \\\n",
    "                                                                   element_for_erosion_and_dilation, \\\n",
    "                                                                   first_erosion_iterations, \\\n",
    "                                                                   first_dilation_iterations, \\\n",
    "                                                                   sobel_kernel_size):\n",
    "    \n",
    "    pre_processed_images = []\n",
    "    clahe = cv2.createCLAHE(clipLimit = clahe_clip_limit, tileGridSize = clahe_tile_grid_size)\n",
    "    \n",
    "    for image in images_list:\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # converte para escala de cinzas\n",
    "        blured_image = cv2.medianBlur(grayscale_image, median_blur_kernel_size) # aplica filtro de mediana\n",
    "        clahe_image = clahe.apply(blured_image) # aplica equalizacao de histograma por blocos, uniformiza iluminacao\n",
    "        min_pixel_value = np.min(clahe_image) # obtem o pixel de menor valor na imagem\n",
    "        darker_image = clahe_image - min_pixel_value # escurece toda a imagem, subtraindo o valor do menor pixel\n",
    "        \n",
    "        erosion_image = cv2.erode(darker_image, \\\n",
    "                                  element_for_erosion_and_dilation, \\\n",
    "                                  iterations = first_erosion_iterations) # aplica 2 erosoes\n",
    "        \n",
    "        dilated_image = cv2.dilate(erosion_image, \\\n",
    "                                   element_for_erosion_and_dilation, \\\n",
    "                                   iterations = first_dilation_iterations) # aplica 2 dilatacoes\n",
    "        \n",
    "        gradient_x = cv2.Sobel(dilated_image, cv2.CV_64F, 1, 0, ksize=sobel_kernel_size)\n",
    "        gradient_y = cv2.Sobel(dilated_image, cv2.CV_64F, 0, 1, ksize=sobel_kernel_size)\n",
    "        gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "        gradient_magnitude = cv2.convertScaleAbs(gradient_magnitude) # obtém o filtro sobel horizontal e vertical\n",
    "        \n",
    "        pre_processed_images.append(gradient_magnitude)\n",
    "        \n",
    "    return pre_processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6e240492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_with_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                             images_list, \\\n",
    "                                                             median_blur_kernel_size, \\\n",
    "                                                             clahe_clip_limit, \\\n",
    "                                                             clahe_tile_grid_size, \\\n",
    "                                                             element_for_erosion_and_dilation, \\\n",
    "                                                             first_erosion_iterations, \\\n",
    "                                                             first_dilation_iterations):\n",
    "    \n",
    "    pre_processed_images = []\n",
    "    clahe = cv2.createCLAHE(clipLimit = clahe_clip_limit, tileGridSize = clahe_tile_grid_size)\n",
    "    \n",
    "    for image in images_list:\n",
    "        blured_image = cv2.medianBlur(image, median_blur_kernel_size) # aplica filtro de mediana\n",
    "        img_lab = cv2.cvtColor(blured_image, cv2.COLOR_RGB2Lab)\n",
    "        img_lab[:,:,0] = clahe.apply(img_lab[:,:,0])\n",
    "        clahe_image = cv2.cvtColor(img_lab, cv2.COLOR_Lab2RGB)\n",
    "        \n",
    "        min_pixel_value = np.min(clahe_image) # obtem o pixel de menor valor na imagem\n",
    "        darker_image = clahe_image - min_pixel_value # escurece toda a imagem, subtraindo o valor do menor pixel\n",
    "        \n",
    "        erosion_image = cv2.erode(darker_image, \\\n",
    "                                  element_for_erosion_and_dilation, \\\n",
    "                                  iterations = first_erosion_iterations) # aplica n erosoes\n",
    "        \n",
    "        dilated_image = cv2.dilate(erosion_image, \\\n",
    "                                   element_for_erosion_and_dilation, \\\n",
    "                                   iterations = first_dilation_iterations) # aplica n dilatacoes\n",
    "        \n",
    "        pre_processed_images.append(dilated_image)\n",
    "        \n",
    "    return pre_processed_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fd197",
   "metadata": {},
   "source": [
    "## Demais funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a1f5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_name_list(base_dir, list_with_names, default_image_width, default_image_height):\n",
    "    loaded_images = []\n",
    "    for image_name in list_with_names:\n",
    "        im = cv2.imread(base_dir + image_name)\n",
    "        im_correct_colorscheme = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        im_resized = cv2.resize(im_correct_colorscheme, (default_image_width, default_image_height))\n",
    "        loaded_images.append(im_resized)\n",
    "    return loaded_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "456d6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(base_dir, images_list, images_names_list, image_name_prefix, directory_to_save):\n",
    "    for idx in range(len(images_names_list)):\n",
    "        \n",
    "        if not os.path.exists(base_dir + directory_to_save):\n",
    "            os.makedirs(base_dir + directory_to_save)\n",
    "            \n",
    "        cv2.imwrite(base_dir + directory_to_save + '/' + image_name_prefix + images_names_list[idx], images_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75a30725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_labels(pre_processed_train_crack, pre_processed_train_non_crack):\n",
    "    input_masks = []\n",
    "    input_masks.extend(pre_processed_train_crack)\n",
    "    input_masks.extend(pre_processed_train_non_crack) # adicionamos todas as imagens à lista de input do modelo\n",
    "    input_labels = []\n",
    "    input_labels.extend(np.ones((len(pre_processed_train_crack), ), np.uint8))\n",
    "    input_labels.extend(np.zeros((len(pre_processed_train_non_crack), ), np.uint8)) # adicionamos as labels das imagens\n",
    "\n",
    "    input_masks = list(map(lambda x:x.flatten(), input_masks)) # aqui, redimensionamos as imagens para terem 1 dimensao\n",
    "\n",
    "    zipped_list_for_shuffle = list(zip(input_masks, input_labels))\n",
    "    random.shuffle(zipped_list_for_shuffle)\n",
    "    \n",
    "    shuffled_input_masks, shuffled_input_labels = zip(*zipped_list_for_shuffle)\n",
    "    \n",
    "    return list(shuffled_input_masks), list(shuffled_input_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94ab18",
   "metadata": {},
   "source": [
    "## Carregando conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cf29736",
   "metadata": {},
   "outputs": [],
   "source": [
    "crack_images_for_train_name_list = os.listdir(base_dir_train_crack)\n",
    "non_crack_images_for_train_name_list = os.listdir(base_dir_train_non_crack)\n",
    "\n",
    "crack_images_for_test_name_list = os.listdir(base_dir_test_crack)\n",
    "non_crack_images_for_test_name_list = os.listdir(base_dir_test_non_crack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ad863f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "crack_images_for_train_list = load_images_from_name_list(base_dir_train_crack, \\\n",
    "                                                         crack_images_for_train_name_list, \\\n",
    "                                                         default_image_width, default_image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42d9657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_crack_images_for_train_list = load_images_from_name_list(base_dir_train_non_crack, \\\n",
    "                                                             non_crack_images_for_train_name_list, \\\n",
    "                                                             default_image_width, default_image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1201526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crack_images_for_test_list = load_images_from_name_list(base_dir_test_crack, \\\n",
    "                                                         crack_images_for_test_name_list, \\\n",
    "                                                         default_image_width, default_image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7de24964",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_crack_images_for_test_list = load_images_from_name_list(base_dir_test_non_crack, \\\n",
    "                                                             non_crack_images_for_test_name_list, \\\n",
    "                                                             default_image_width, default_image_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596be86",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a001e",
   "metadata": {},
   "source": [
    "### Pré-processamento 1: Conversão escala de cinzas, filtro mediana, CLAHE, escurecimento, erosão e dilatação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bee07f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_crack_1 = pre_process_with_grayscale_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                                                       crack_images_for_train_list, \\\n",
    "                                                                                       median_blur_kernel_size, \\\n",
    "                                                                                       clahe_clip_limit, \\\n",
    "                                                                                       clahe_tile_grid_size, \\\n",
    "                                                                                       element_for_erosion_and_dilation, \\\n",
    "                                                                                       first_erosion_iterations, \\\n",
    "                                                                                       first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae3681da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_non_crack_1 = pre_process_with_grayscale_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                                                           non_crack_images_for_train_list, \\\n",
    "                                                                                           median_blur_kernel_size, \\\n",
    "                                                                                           clahe_clip_limit, \\\n",
    "                                                                                           clahe_tile_grid_size, \\\n",
    "                                                                                           element_for_erosion_and_dilation, \\\n",
    "                                                                                           first_erosion_iterations, \\\n",
    "                                                                                           first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c75d5341",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_crack_1 = pre_process_with_grayscale_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                                                       crack_images_for_test_list, \\\n",
    "                                                                                       median_blur_kernel_size, \\\n",
    "                                                                                       clahe_clip_limit, \\\n",
    "                                                                                       clahe_tile_grid_size, \\\n",
    "                                                                                       element_for_erosion_and_dilation, \\\n",
    "                                                                                       first_erosion_iterations, \\\n",
    "                                                                                       first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c865b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_non_crack_1 = pre_process_with_grayscale_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                                                           non_crack_images_for_test_list, \\\n",
    "                                                                                           median_blur_kernel_size, \\\n",
    "                                                                                           clahe_clip_limit, \\\n",
    "                                                                                           clahe_tile_grid_size, \\\n",
    "                                                                                           element_for_erosion_and_dilation, \\\n",
    "                                                                                           first_erosion_iterations, \\\n",
    "                                                                                           first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba10a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_crack_1, \\\n",
    "            crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'crack_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6180555",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_non_crack_1, \\\n",
    "            non_crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'non-crack_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b92c3b",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ac216da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_1, input_labels_1 = get_data_and_labels(pre_processed_train_crack_1, pre_processed_train_non_crack_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be94011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_1 = SVC()\n",
    "grid_search_svm_1 = GridSearchCV(svm_model_1, svm_param_grid_for_search, cv=5, scoring='accuracy')\n",
    "grid_search_svm_1.fit(input_data_1, input_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e4334bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1, test_labels_1 = get_data_and_labels(pre_processed_test_crack_1, pre_processed_test_non_crack_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dada2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters SVM 1: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Accuracy SVM 1: 0.8333333333333333\n",
      "Test Set Accuracy SVM 1: 0.8407643312101911\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters SVM 1:\", grid_search_svm_1.best_params_)\n",
    "print(\"Best Accuracy SVM 1:\", grid_search_svm_1.best_score_)\n",
    "best_svm_model_1 = grid_search_svm_1.best_estimator_\n",
    "accuracy_1 = best_svm_model_1.score(test_data_1, test_labels_1)\n",
    "print(\"Test Set Accuracy SVM 1:\", accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdf5d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_prediction_1 = best_svm_model_1.predict(test_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4847793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_svm_1 = accuracy_score(svm_test_prediction_1, test_labels_1)\n",
    "precision_svm_1 = precision_score(test_labels_1, svm_test_prediction_1)\n",
    "recall_svm_1 = recall_score(test_labels_1, svm_test_prediction_1)\n",
    "f1_svm_1 = f1_score(svm_test_prediction_1, test_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a5aa0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8513513513513513\n",
      "Recall: 0.8181818181818182\n",
      "F1-SCORE: 0.8344370860927152\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\", precision_svm_1)\n",
    "print(\"Recall:\", recall_svm_1)\n",
    "print(\"F1-SCORE:\", f1_svm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d04dd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69, 14],\n",
       "       [11, 63]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_svm_1 = confusion_matrix(svm_test_prediction_1, test_labels_1)\n",
    "conf_matrix_svm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94e95e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained-models/preprocess1_svm_model.pkl']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_svm_model_1, base_dir_trained_models + 'preprocess1_' + svm_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81c622",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a366d7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [None, 10, 20],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_1 = RandomForestClassifier()\n",
    "grid_search_rf_1 = GridSearchCV(rf_model_1, rf_param_grid_for_search, cv=5, scoring='accuracy')\n",
    "grid_search_rf_1.fit(input_data_1, input_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd32e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters RF 1: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Accuracy RF 1: 0.8300000000000001\n",
      "Test Set Accuracy: 0.8407643312101911\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters RF 1:\", grid_search_rf_1.best_params_)\n",
    "print(\"Best Accuracy RF 1:\", grid_search_rf_1.best_score_)\n",
    "best_model_rf_1 = grid_search_rf_1.best_estimator_\n",
    "accuracy_rf_1 = best_model_rf_1.score(test_data_1, test_labels_1)\n",
    "print(\"Test Set Accuracy:\", accuracy_rf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "309a5a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_prediction_1 = best_model_rf_1.predict(test_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05f49215",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_rf_1 = precision_score(test_labels_1, rf_test_prediction_1)\n",
    "recall_rf_1 = recall_score(test_labels_1, rf_test_prediction_1)\n",
    "f1_rf_1 = f1_score(rf_test_prediction_1, test_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b32a0915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision RF 1: 0.8095238095238095\n",
      "Recall RF 1: 0.8831168831168831\n",
      "F1-SCORE RF 1: 0.84472049689441\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision RF 1:\", precision_rf_1)\n",
    "print(\"Recall RF 1:\", recall_rf_1)\n",
    "print(\"F1-SCORE RF 1:\", f1_rf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0c429a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64,  9],\n",
       "       [16, 68]], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_rf_1 = confusion_matrix(rf_test_prediction_1, test_labels_1)\n",
    "conf_matrix_rf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "72c67d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained-models/preprocess1_rf_model.pkl']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model_rf_1, base_dir_trained_models + 'preprocess1_' + rf_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abeecac",
   "metadata": {},
   "source": [
    "#### Modelo híbrido (StackingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3e24e985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf',\n",
       "                                RandomForestClassifier(max_depth=10,\n",
       "                                                       min_samples_split=5)),\n",
       "                               ('svm', SVC(C=10))],\n",
       "                   final_estimator=RandomForestClassifier())"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model_1 = StackingClassifier(estimators=[('rf', best_model_rf_1), ('svm', best_svm_model_1)], \\\n",
    "                                     final_estimator=RandomForestClassifier())\n",
    "stacked_model_1.fit(input_data_1, input_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9d9609d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_predictions_1 = stacked_model_1.predict(test_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "98aacb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_s_1 = accuracy_score(sc_predictions_1, test_labels_1)\n",
    "precision_s_1 = precision_score(test_labels_1, sc_predictions_1)\n",
    "recall_s_1 = recall_score(test_labels_1, sc_predictions_1)\n",
    "f1_s_1 = f1_score(sc_predictions_1, test_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e41f1725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy SM 1: 0.7770700636942676\n",
      "Precision SM 1: 0.7837837837837838\n",
      "Recall SM 1: 0.7532467532467533\n",
      "F1-SCORE SM 1: 0.7682119205298014\n"
     ]
    }
   ],
   "source": [
    "print(\"Acurracy SM 1:\", accuracy_s_1)\n",
    "print(\"Precision SM 1:\", precision_s_1)\n",
    "print(\"Recall SM 1:\", recall_s_1)\n",
    "print(\"F1-SCORE SM 1:\", f1_s_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e63bb9",
   "metadata": {},
   "source": [
    "#### Modelo híbrido (VotationClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "33be89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_votation = SVC(probability=True, C = 10, gamma = 'scale', kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d2250dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, probability=True)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_votation.fit(input_data_1, input_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "027202c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(max_depth=10,\n",
       "                                                     min_samples_split=5)),\n",
       "                             ('svm', SVC(C=10, probability=True))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votation_model_1 = VotingClassifier(estimators=[('rf', best_model_rf_1), ('svm', svm_model_votation)], voting='soft')\n",
    "votation_model_1.fit(input_data_1, input_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "14ff47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_predictions_1 = votation_model_1.predict(test_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0893432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_v_1 = accuracy_score(vt_predictions_1, test_labels_1)\n",
    "precision_v_1 = precision_score(test_labels_1, vt_predictions_1)\n",
    "recall_v_1 = recall_score(test_labels_1, vt_predictions_1)\n",
    "f1_v_1 = f1_score(vt_predictions_1, test_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bad3ec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy SM 1: 0.8535031847133758\n",
      "Precision SM 1: 0.8214285714285714\n",
      "Recall SM 1: 0.8961038961038961\n",
      "F1-SCORE SM 1: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Acurracy SM 1:\", accuracy_v_1)\n",
    "print(\"Precision SM 1:\", precision_v_1)\n",
    "print(\"Recall SM 1:\", recall_v_1)\n",
    "print(\"F1-SCORE SM 1:\", f1_v_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0552e564",
   "metadata": {},
   "source": [
    "### Pré-processamento 2: Conversão escala de cinzas, filtro mediana, CLAHE, escurecimento, erosão, dilatação e threshold adaptativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "275cd889",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_crack_2 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_adaptthreshold( \\\n",
    "                                                                            crack_images_for_train_list, \\\n",
    "                                                                            median_blur_kernel_size, \\\n",
    "                                                                            clahe_clip_limit, \\\n",
    "                                                                            clahe_tile_grid_size, \\\n",
    "                                                                            element_for_erosion_and_dilation, \\\n",
    "                                                                            first_erosion_iterations, \\\n",
    "                                                                            first_dilation_iterations, \\\n",
    "                                                                            adapt_thresh_neighbour_size, \\\n",
    "                                                                            adapt_thresh_subtraction_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b820b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_non_crack_2 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_adaptthreshold( \\\n",
    "                                                                            non_crack_images_for_train_list, \\\n",
    "                                                                            median_blur_kernel_size, \\\n",
    "                                                                            clahe_clip_limit, \\\n",
    "                                                                            clahe_tile_grid_size, \\\n",
    "                                                                            element_for_erosion_and_dilation, \\\n",
    "                                                                            first_erosion_iterations, \\\n",
    "                                                                            first_dilation_iterations, \\\n",
    "                                                                            adapt_thresh_neighbour_size, \\\n",
    "                                                                            adapt_thresh_subtraction_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a0c8ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_crack_2 = pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_adaptthreshold( \\\n",
    "                                                                            crack_images_for_test_list, \\\n",
    "                                                                            median_blur_kernel_size, \\\n",
    "                                                                            clahe_clip_limit, \\\n",
    "                                                                            clahe_tile_grid_size, \\\n",
    "                                                                            element_for_erosion_and_dilation, \\\n",
    "                                                                            first_erosion_iterations, \\\n",
    "                                                                            first_dilation_iterations, \\\n",
    "                                                                            adapt_thresh_neighbour_size, \\\n",
    "                                                                            adapt_thresh_subtraction_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9a6b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_non_crack_2 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_adaptthreshold( \\\n",
    "                                                                            non_crack_images_for_test_list, \\\n",
    "                                                                            median_blur_kernel_size, \\\n",
    "                                                                            clahe_clip_limit, \\\n",
    "                                                                            clahe_tile_grid_size, \\\n",
    "                                                                            element_for_erosion_and_dilation, \\\n",
    "                                                                            first_erosion_iterations, \\\n",
    "                                                                            first_dilation_iterations, \\\n",
    "                                                                            adapt_thresh_neighbour_size, \\\n",
    "                                                                            adapt_thresh_subtraction_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b581c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_crack_2, \\\n",
    "            crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'crack_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "584cb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_non_crack_2, \\\n",
    "            non_crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'non-crack_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd86068",
   "metadata": {},
   "source": [
    "Obtendo dados e labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbd33b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_2, input_labels_2 = get_data_and_labels(pre_processed_train_crack_2, pre_processed_train_non_crack_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "881c0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2, test_labels_2 = get_data_and_labels(pre_processed_test_crack_2, pre_processed_test_non_crack_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9161bd2",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "580b1f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_2 = SVC()\n",
    "grid_search_svm_2 = GridSearchCV(svm_model_2, svm_param_grid_for_search, cv=5, scoring='accuracy')\n",
    "grid_search_svm_2.fit(input_data_2, input_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd5cbf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters SVM 2: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Accuracy SVM 2: 0.7150000000000001\n",
      "Test Set Accuracy SVM 2: 0.6687898089171974\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters SVM 2:\", grid_search_svm_2.best_params_)\n",
    "print(\"Best Accuracy SVM 2:\", grid_search_svm_2.best_score_)\n",
    "best_svm_model_2 = grid_search_svm_2.best_estimator_\n",
    "accuracy_2 = best_svm_model_2.score(test_data_2, test_labels_2)\n",
    "print(\"Test Set Accuracy SVM 2:\", accuracy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4388864",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_prediction_2 = best_svm_model_2.predict(test_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ac52903",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_svm_2 = precision_score(test_labels_2, svm_test_prediction_2)\n",
    "recall_svm_2 = recall_score(test_labels_2, svm_test_prediction_2)\n",
    "f1_svm_2 = f1_score(svm_test_prediction_2, test_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b65a598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6436781609195402\n",
      "Recall: 0.7272727272727273\n",
      "F1-SCORE: 0.6829268292682927\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\", precision_svm_2)\n",
    "print(\"Recall:\", recall_svm_2)\n",
    "print(\"F1-SCORE:\", f1_svm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc2e0d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49, 21],\n",
       "       [31, 56]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_svm_2 = confusion_matrix(svm_test_prediction_2, test_labels_2)\n",
    "conf_matrix_svm_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b3b635",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "49164626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [10, 20], 'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [3, 7],\n",
       "                         'n_estimators': [150, 250]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_2 = RandomForestClassifier()\n",
    "grid_search_rf_2 = GridSearchCV(rf_model_2, rf_param_grid_for_search, cv=5, scoring='accuracy')\n",
    "grid_search_rf_2.fit(input_data_2, input_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "27bc98fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters RF 2: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 7, 'n_estimators': 250}\n",
      "Best Accuracy RF 2: 0.72\n",
      "Test Set Accuracy RF 2: 0.6496815286624203\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters RF 2:\", grid_search_rf_2.best_params_)\n",
    "print(\"Best Accuracy RF 2:\", grid_search_rf_2.best_score_)\n",
    "best_model_rf_2 = grid_search_rf_2.best_estimator_\n",
    "accuracy_rf_2 = best_model_rf_2.score(test_data_2, test_labels_2)\n",
    "print(\"Test Set Accuracy RF 2:\", accuracy_rf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a194226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_prediction_2 = best_model_rf_2.predict(test_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dab7f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_rf_2 = precision_score(test_labels_2, rf_test_prediction_2)\n",
    "recall_rf_2 = recall_score(test_labels_2, rf_test_prediction_2)\n",
    "f1_rf_2 = f1_score(rf_test_prediction_2, test_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f2234959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision RF 2: 0.627906976744186\n",
      "Recall RF 2: 0.7012987012987013\n",
      "F1-SCORE RF 2: 0.6625766871165645\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision RF 2:\", precision_rf_2)\n",
    "print(\"Recall RF 2:\", recall_rf_2)\n",
    "print(\"F1-SCORE RF 2:\", f1_rf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cedf8b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48, 23],\n",
       "       [32, 54]], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_rf_2 = confusion_matrix(rf_test_prediction_2, test_labels_2)\n",
    "conf_matrix_rf_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7462e4d",
   "metadata": {},
   "source": [
    "#### Modelo híbrido (StackingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4e73acc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf',\n",
       "                                RandomForestClassifier(max_depth=20,\n",
       "                                                       min_samples_split=7,\n",
       "                                                       n_estimators=250)),\n",
       "                               ('svm', SVC(C=1))],\n",
       "                   final_estimator=RandomForestClassifier())"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model_2 = StackingClassifier(estimators=[('rf', best_model_rf_2), ('svm', best_svm_model_2)], \\\n",
    "                                     final_estimator=RandomForestClassifier())\n",
    "stacked_model_2.fit(input_data_2, input_labels_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df8b552",
   "metadata": {},
   "source": [
    "### Pré-processamento 3: Conversão escala de cinzas, filtro mediana, CLAHE, escurecimento, erosão, dilatação e filtro Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52fbb7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_crack_3 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_sobel( \\\n",
    "                                                                   crack_images_for_train_list, \\\n",
    "                                                                   median_blur_kernel_size, \\\n",
    "                                                                   clahe_clip_limit, \\\n",
    "                                                                   clahe_tile_grid_size, \\\n",
    "                                                                   element_for_erosion_and_dilation, \\\n",
    "                                                                   first_erosion_iterations, \\\n",
    "                                                                   first_dilation_iterations, \\\n",
    "                                                                   sobel_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4102cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_non_crack_3 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_sobel( \\\n",
    "                                                                   non_crack_images_for_train_list, \\\n",
    "                                                                   median_blur_kernel_size, \\\n",
    "                                                                   clahe_clip_limit, \\\n",
    "                                                                   clahe_tile_grid_size, \\\n",
    "                                                                   element_for_erosion_and_dilation, \\\n",
    "                                                                   first_erosion_iterations, \\\n",
    "                                                                   first_dilation_iterations, \\\n",
    "                                                                   sobel_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba3ef622",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_crack_3 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_sobel( \\\n",
    "                                                                   crack_images_for_test_list, \\\n",
    "                                                                   median_blur_kernel_size, \\\n",
    "                                                                   clahe_clip_limit, \\\n",
    "                                                                   clahe_tile_grid_size, \\\n",
    "                                                                   element_for_erosion_and_dilation, \\\n",
    "                                                                   first_erosion_iterations, \\\n",
    "                                                                   first_dilation_iterations, \\\n",
    "                                                                   sobel_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "12800512",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_non_crack_3 = \\\n",
    "    pre_process_with_grayscale_median_clahe_darkening_erosion_dilation_sobel( \\\n",
    "                                                                   non_crack_images_for_test_list, \\\n",
    "                                                                   median_blur_kernel_size, \\\n",
    "                                                                   clahe_clip_limit, \\\n",
    "                                                                   clahe_tile_grid_size, \\\n",
    "                                                                   element_for_erosion_and_dilation, \\\n",
    "                                                                   first_erosion_iterations, \\\n",
    "                                                                   first_dilation_iterations, \\\n",
    "                                                                   sobel_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd8d32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_crack_3, \\\n",
    "            crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'crack_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "597527ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_non_crack_3, \\\n",
    "            non_crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'non-crack_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1427859f",
   "metadata": {},
   "source": [
    "Obtendo dados e labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73d91d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_3, input_labels_3 = get_data_and_labels(pre_processed_train_crack_3, pre_processed_train_non_crack_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b4c927e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_3, test_labels_3 = get_data_and_labels(pre_processed_test_crack_3, pre_processed_test_non_crack_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7643b",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "146da8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_3 = SVC()\n",
    "grid_search_svm_3 = GridSearchCV(svm_model_3, svm_param_grid_for_search, cv=5, scoring='accuracy')\n",
    "grid_search_svm_3.fit(input_data_3, input_labels_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "55e07957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters SVM 3: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Accuracy SVM 3: 0.8666666666666666\n",
      "Test Set Accuracy SVM 3: 0.821656050955414\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters SVM 3:\", grid_search_svm_3.best_params_)\n",
    "print(\"Best Accuracy SVM 3:\", grid_search_svm_3.best_score_)\n",
    "best_svm_model_3 = grid_search_svm_3.best_estimator_\n",
    "accuracy_3 = best_svm_model_3.score(test_data_3, test_labels_3)\n",
    "print(\"Test Set Accuracy SVM 3:\", accuracy_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34b028c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_prediction_3 = best_svm_model_3.predict(test_data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "04929ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_svm_3 = precision_score(test_labels_3, svm_test_prediction_3)\n",
    "recall_svm_3 = recall_score(test_labels_3, svm_test_prediction_3)\n",
    "f1_svm_3 = f1_score(svm_test_prediction_3, test_labels_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d67d0e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8024691358024691\n",
      "Recall: 0.8441558441558441\n",
      "F1-SCORE: 0.8227848101265822\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\", precision_svm_3)\n",
    "print(\"Recall:\", recall_svm_3)\n",
    "print(\"F1-SCORE:\", f1_svm_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a4c05a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64, 12],\n",
       "       [16, 65]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_svm_3 = confusion_matrix(svm_test_prediction_3, test_labels_3)\n",
    "conf_matrix_svm_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df38f65",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8868ba53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [10, 20], 'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [3, 7],\n",
       "                         'n_estimators': [150, 250]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_3 = RandomForestClassifier()\n",
    "grid_search_rf_3 = GridSearchCV(rf_model_3, rf_param_grid_for_search, cv=5, scoring='accuracy')\n",
    "grid_search_rf_3.fit(input_data_3, input_labels_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "abc0dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters RF 3: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 250}\n",
      "Best Accuracy RF 3: 0.8116666666666668\n",
      "Test Set Accuracy RF 3: 0.7197452229299363\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters RF 3:\", grid_search_rf_3.best_params_)\n",
    "print(\"Best Accuracy RF 3:\", grid_search_rf_3.best_score_)\n",
    "best_model_rf_3 = grid_search_rf_3.best_estimator_\n",
    "accuracy_rf_3 = best_model_rf_3.score(test_data_3, test_labels_3)\n",
    "print(\"Test Set Accuracy RF 3:\", accuracy_rf_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b3e68ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_prediction_3 = best_model_rf_3.predict(test_data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "65ccad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_rf_3 = precision_score(test_labels_3, rf_test_prediction_3)\n",
    "recall_rf_3 = recall_score(test_labels_3, rf_test_prediction_3)\n",
    "f1_rf_3 = f1_score(rf_test_prediction_3, test_labels_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5e1776f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision RF 3: 0.7037037037037037\n",
      "Recall RF 3: 0.7402597402597403\n",
      "F1-SCORE RF 3: 0.7215189873417721\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision RF 3:\", precision_rf_3)\n",
    "print(\"Recall RF 3:\", recall_rf_3)\n",
    "print(\"F1-SCORE RF 3:\", f1_rf_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5bba7c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56, 20],\n",
       "       [24, 57]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_rf_3 = confusion_matrix(rf_test_prediction_3, test_labels_3)\n",
    "conf_matrix_rf_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59eaf68",
   "metadata": {},
   "source": [
    "### Pré-processamento 3: Filtro mediana, CLAHE, escurecimento, erosão, dilatação e filtro Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2fbf2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_crack_4 = \\\n",
    "    pre_process_with_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                       crack_images_for_train_list, \\\n",
    "                                                       median_blur_kernel_size, \\\n",
    "                                                       clahe_clip_limit, \\\n",
    "                                                       clahe_tile_grid_size, \\\n",
    "                                                       element_for_erosion_and_dilation, \\\n",
    "                                                       first_erosion_iterations, \\\n",
    "                                                       first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "248438a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_non_crack_4 = \\\n",
    "    pre_process_with_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                       non_crack_images_for_train_list, \\\n",
    "                                                       median_blur_kernel_size, \\\n",
    "                                                       clahe_clip_limit, \\\n",
    "                                                       clahe_tile_grid_size, \\\n",
    "                                                       element_for_erosion_and_dilation, \\\n",
    "                                                       first_erosion_iterations, \\\n",
    "                                                       first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "565f9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_crack_4 = \\\n",
    "    pre_process_with_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                           crack_images_for_test_list, \\\n",
    "                                                           median_blur_kernel_size, \\\n",
    "                                                           clahe_clip_limit, \\\n",
    "                                                           clahe_tile_grid_size, \\\n",
    "                                                           element_for_erosion_and_dilation, \\\n",
    "                                                           first_erosion_iterations, \\\n",
    "                                                           first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6ed050cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_non_crack_4 = \\\n",
    "    pre_process_with_median_clahe_darkening_erosion_dilation( \\\n",
    "                                                           non_crack_images_for_test_list, \\\n",
    "                                                           median_blur_kernel_size, \\\n",
    "                                                           clahe_clip_limit, \\\n",
    "                                                           clahe_tile_grid_size, \\\n",
    "                                                           element_for_erosion_and_dilation, \\\n",
    "                                                           first_erosion_iterations, \\\n",
    "                                                           first_dilation_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a5dc8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_crack_4, \\\n",
    "            crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'crack_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f6b6f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(base_dir_processed_train_images, \\\n",
    "            pre_processed_train_non_crack_3, \\\n",
    "            non_crack_images_for_train_name_list, \\\n",
    "            preprocessed_image_name_prefix, \\\n",
    "            'non-crack_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef9f6d",
   "metadata": {},
   "source": [
    "Obtendo dados e labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "08136066",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_4, input_labels_4 = get_data_and_labels(pre_processed_train_crack_4, pre_processed_train_non_crack_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "55b2072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_4, test_labels_4 = get_data_and_labels(pre_processed_test_crack_4, pre_processed_test_non_crack_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b972d0",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_4 = SVC()\n",
    "grid_search_svm_4 = GridSearchCV(svm_model_4, svm_param_grid_for_search, cv=5, scoring='accuracy')\n",
    "grid_search_svm_4.fit(input_data_4, input_labels_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters SVM 4:\", grid_search_svm_4.best_params_)\n",
    "print(\"Best Accuracy SVM 4:\", grid_search_svm_4.best_score_)\n",
    "best_svm_model_4 = grid_search_svm_4.best_estimator_\n",
    "accuracy_4 = best_svm_model_4.score(test_data_4, test_labels_4)\n",
    "print(\"Test Set Accuracy SVM 4:\", accuracy_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_prediction_4 = best_svm_model_4.predict(test_data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_svm_4 = precision_score(test_labels_4, svm_test_prediction_4)\n",
    "recall_svm_4 = recall_score(test_labels_4, svm_test_prediction_4)\n",
    "f1_svm_4 = f1_score(svm_test_prediction_4, test_labels_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43795811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision SVM 4:\", precision_svm_4)\n",
    "print(\"Recall SVM 4:\", recall_svm_4)\n",
    "print(\"F1-SCORE SVM 4:\", f1_svm_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_svm_4 = confusion_matrix(svm_test_prediction_4, test_labels_4)\n",
    "conf_matrix_svm_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2a3e6",
   "metadata": {},
   "source": [
    "## Melhor modelo obtido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_file_name = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa5cd8",
   "metadata": {},
   "source": [
    "## Casos de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8030c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = joblib.load(trained_models_dir + best_model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e09e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "testcase_image_names = []\n",
    "testcase_image_classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c21313",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testing_case_dir + testing_case_csv_file_name, 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    \n",
    "    next(csv_reader)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        testcase_image_names.append(row[0])\n",
    "        testcase_image_classes.append(int(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad741ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "testcase_images = load_images_from_name_list( \\\n",
    "                                         testing_case_dir, \\\n",
    "                                         testcase_image_names, \\\n",
    "                                         default_image_width, default_image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_testcase_images = pre_process_images_from_list( \\\n",
    "                                                         testcase_images, \\\n",
    "                                                         median_blur_kernel_size, \\\n",
    "                                                         clahe_clip_limit, \\\n",
    "                                                         clahe_tile_grid_size, \\\n",
    "                                                         first_erosion_iterations, \\\n",
    "                                                         element_for_erosion_and_dilation, \\\n",
    "                                                         first_dilation_iterations, \\\n",
    "                                                         addapt_thresh_neighbour_size, \\\n",
    "                                                         addapt_thresh_subtraction_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d22c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_testcase_data = list(map(lambda x:x.flatten(), pre_processed_testcase_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "testcase_predictions = best_model.predict(input_testcase_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9750d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testcase_accuracy = accuracy_score(testcase_predictions, testcase_image_classes)\n",
    "testcase_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0883a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testcase_conf_matrix = confusion_matrix(testcase_predictions, testcase_image_classes)\n",
    "testcase_conf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
