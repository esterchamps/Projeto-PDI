{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fa8a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1602022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models_dir = 'trained-models/'\n",
    "testing_case_dir = 'testing-case-example/Testing/'\n",
    "testing_case_csv_file_name = 'Testing.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f3b7e8",
   "metadata": {},
   "source": [
    "Carregando modelos treinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "603b52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = joblib.load(trained_models_dir + 'svm_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6535ea3f",
   "metadata": {},
   "source": [
    "Carregando informações do .CSV com os casos de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a93ccd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_names = []\n",
    "test_image_classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc0f873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testing_case_dir + testing_case_csv_file_name, 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    \n",
    "    next(csv_reader)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        test_image_names.append(row[0])\n",
    "        test_image_classes.append(int(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66574f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_name_list(base_dir, list_with_names, default_image_width, default_image_height, cv2_imread_colorscheme):\n",
    "    loaded_images = []\n",
    "    for image_name in list_with_names:\n",
    "        im = cv2.imread(base_dir + image_name, cv2_imread_colorscheme)\n",
    "        im_resized = cv2.resize(im, (default_image_width, default_image_height))\n",
    "        loaded_images.append(im_resized)\n",
    "    return loaded_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bfdbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = load_images_from_name_list(testing_case_dir, \\\n",
    "                                         test_image_names, \\\n",
    "                                         256, 256, \\\n",
    "                                         cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06f38a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_images_from_list(images_list, \\\n",
    "                                 median_blur_kernel_size, \\\n",
    "                                 clahe_clip_limit, \\\n",
    "                                 clahe_tile_grid_size, \\\n",
    "                                 first_erosion_iterations, \\\n",
    "                                 element_for_erosion_and_dilation, \\\n",
    "                                 first_dilation_iterations, \\\n",
    "                                 addapt_thresh_neighbour_size, addapt_thresh_subtraction_constant):\n",
    "    \n",
    "    pre_processed_images = []\n",
    "    clahe = cv2.createCLAHE(clipLimit = clahe_clip_limit, tileGridSize = clahe_tile_grid_size)\n",
    "    \n",
    "    for image in images_list:\n",
    "        blured_image = cv2.medianBlur(image, median_blur_kernel_size) # aplica filtro de mediana\n",
    "        clahe_image = clahe.apply(blured_image) # aplica equalizacao de histograma por blocos, uniformiza iluminacao\n",
    "        min_pixel_value = np.min(clahe_image) # obtem o pixel de menor valor na imagem\n",
    "        darker_image = clahe_image - min_pixel_value # escurece toda a imagem, subtraindo o valor do menor pixel\n",
    "        \n",
    "        erosion_image = cv2.erode(darker_image, \\\n",
    "                                  element_for_erosion_and_dilation, \\\n",
    "                                  iterations = first_erosion_iterations) # aplica 2 erosoes\n",
    "        \n",
    "        dilated_image = cv2.dilate(erosion_image, \\\n",
    "                                   element_for_erosion_and_dilation, \\\n",
    "                                   iterations = first_dilation_iterations) # aplica 2 dilatacoes\n",
    "        \n",
    "        image_threshold = cv2.adaptiveThreshold(dilated_image, 255, \\\n",
    "                                                cv2.ADAPTIVE_THRESH_MEAN_C, \\\n",
    "                                                cv2.THRESH_BINARY, \\\n",
    "                                                addapt_thresh_neighbour_size, \\\n",
    "                                                addapt_thresh_subtraction_constant)\n",
    "        \n",
    "        #image_negative = cv2.bitwise_not(image_threshold)\n",
    "        pre_processed_images.append(image_threshold)\n",
    "        \n",
    "    return pre_processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7156c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_blur_kernel_size = 3\n",
    "clahe_clip_limit = 4.0\n",
    "clahe_tile_grid_size = (30, 30)\n",
    "first_erosion_iterations = 3\n",
    "first_dilation_iterations = 2\n",
    "size_for_erosion_and_dilation_element = 2\n",
    "\n",
    "element_for_erosion_and_dilation = \\\n",
    "    cv2.getStructuringElement(cv2.MORPH_CROSS, \\\n",
    "                              (2 * size_for_erosion_and_dilation_element + 1, 2 * size_for_erosion_and_dilation_element + 1), \\\n",
    "                              (size_for_erosion_and_dilation_element, size_for_erosion_and_dilation_element))\n",
    "\n",
    "addapt_thresh_neighbour_size = 11\n",
    "addapt_thresh_subtraction_constant = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aff2101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_images = pre_process_images_from_list(test_images, \\\n",
    "                                                         median_blur_kernel_size, \\\n",
    "                                                         clahe_clip_limit, \\\n",
    "                                                         clahe_tile_grid_size, \\\n",
    "                                                         first_erosion_iterations, \\\n",
    "                                                         element_for_erosion_and_dilation, \\\n",
    "                                                         first_dilation_iterations, \\\n",
    "                                                         addapt_thresh_neighbour_size, \\\n",
    "                                                         addapt_thresh_subtraction_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2090d0bb",
   "metadata": {},
   "source": [
    "Executando modelo SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc8a9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_masks = list(map(lambda x:x.flatten(), pre_processed_test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f46d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm_model.predict(input_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0797f963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(svm_predictions, test_image_classes)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e94e267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [4, 6]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(svm_predictions, test_image_classes)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16327907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
